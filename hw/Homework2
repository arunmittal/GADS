Homework 2
-----------

a) Download the wine dataset from UCI repository:

http://archive.ics.uci.edu/ml/datasets/Wine

i) Perform cross-validation to pick the best value for k. 

ii) Perform cross-validation to pick the best model between logistic regression and kNN. Does the answer change when you use a different CV technique? 


b) Bias-Variance Framework


The example aims to illustrate bias-variance framework. Remember, the goal is not only to have a better in-sample fit. The ultimate goal is to achieve a respectable Eout. Hence, the model selection should depend be a function of the dataset, not the target complexity. 

Consider a case where target function is given by sin( Ï€ x ) where the input distribution is uniform on [ -1, 1 ]. Assume that the training set has two examples and the learning algorithm tries to minize the root mean squared error.

Assume that we have two learning models consisting of all hypothesis in the form of:

	h(x) = ax + b
	h(x) = b

	* Run 10,000 random trials and fit the hypothesis each time. A random trial will look like this:

![N=2](http://gads06.s3-website-us-east-1.amazonaws.com/images/Bias-Variance-2)


	What is the average hypothesis for each model? 

	* What are the bias and variance for each model? Which model generalizes better out-of-sample? 

Hints:
	i)	The graphs on the left illustrate each trial for each model. The charts on the right depict average hypotesis and variance around each model. 

![Bias and Variance - simple model](http://gads06.s3-website-us-east-1.amazonaws.com/images/Bias-Variance-3)
![Bias and Variance - complex model](http://gads06.s3-website-us-east-1.amazonaws.com/images/Bias-Variance-4)

	ii) RMSE can be defined as:

	def rmse(y,h):
    	return(np.sqrt(np.mean(np.square(y-h))))

    where y's are the target function variables and h's are your predictions based on your hypothesis. 

